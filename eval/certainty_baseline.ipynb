{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a154b-4df9-4e73-a608-73e03bf4f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "experiment_name = 'Baseline-async'\n",
    "mlflow.set_tracking_uri('http://localhost/')\n",
    "artifact_dir = 'H:\\\\mlruns_2\\\\'\n",
    "source_dir = '../../zimp_orchestrator/orch/resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c05762-1b61-4315-ba23-634b9d677000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32c6c37a0bab47a0aa9ac7781b7bf6f1</td>\n",
       "      <td>DECISION_TREE</td>\n",
       "      <td>TREC-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98835f555a34424082c805cabdd44d15</td>\n",
       "      <td>DECISION_TREE</td>\n",
       "      <td>DBP-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e477a4ba4dac4717b2d51da6beb0bc9f</td>\n",
       "      <td>DECISION_TREE</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abebe1eb2560436f9a5a4db6a79e10fe</td>\n",
       "      <td>DECISION_TREE</td>\n",
       "      <td>DBP-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c5ed70970754259a0538395a85a1a61</td>\n",
       "      <td>DECISION_TREE</td>\n",
       "      <td>TREC-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>52b3ce034aa64cef9c70b30c91a75405</td>\n",
       "      <td>BERT</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>8af23752f0a040dcb93939e0926a6c8f</td>\n",
       "      <td>BERT</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3594b51440bc449b9129a27199488c1c</td>\n",
       "      <td>BERT</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>8de36d8d26ec4bcb9c62983934487f65</td>\n",
       "      <td>BERT</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>856299f856b04c1db2a0fb54dd57eff9</td>\n",
       "      <td>BERT</td>\n",
       "      <td>YELP-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               run_id     model_type dataset\n",
       "0    32c6c37a0bab47a0aa9ac7781b7bf6f1  DECISION_TREE  TREC-6\n",
       "1    98835f555a34424082c805cabdd44d15  DECISION_TREE  DBP-14\n",
       "2    e477a4ba4dac4717b2d51da6beb0bc9f  DECISION_TREE  YELP-5\n",
       "3    abebe1eb2560436f9a5a4db6a79e10fe  DECISION_TREE  DBP-14\n",
       "4    5c5ed70970754259a0538395a85a1a61  DECISION_TREE  TREC-6\n",
       "..                                ...            ...     ...\n",
       "241  52b3ce034aa64cef9c70b30c91a75405           BERT  YELP-5\n",
       "242  8af23752f0a040dcb93939e0926a6c8f           BERT  YELP-5\n",
       "243  3594b51440bc449b9129a27199488c1c           BERT  YELP-5\n",
       "244  8de36d8d26ec4bcb9c62983934487f65           BERT  YELP-5\n",
       "245  856299f856b04c1db2a0fb54dd57eff9           BERT  YELP-5\n",
       "\n",
       "[246 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "df_exp = mlflow.search_runs(experiment_ids=[experiment.experiment_id], filter_string='attributes.status=\"FINISHED\"')\n",
    "\n",
    "df_exp = df_exp[['run_id', 'params.model_type', 'params.dataset']].rename(columns={'params.model_type': 'model_type', 'params.dataset': 'dataset'})\n",
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdb1281-5466-4a6b-b933-95ec1c6b8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_scores(run_id):\n",
    "    '''\n",
    "    returns dataframes sorted by descending size\n",
    "    in our case the training set is always bigger and therfor the first to be returned\n",
    "    '''\n",
    "    prediction_files = glob.glob(artifact_dir + run_id + '/artifacts/predictions*.csv')\n",
    "    dfs = [pd.read_csv(file)[['prediction', 'certainty']] for file in prediction_files]\n",
    "    dfs = sorted(dfs, key=lambda df: df.shape[0], reverse=True)\n",
    "    return dfs\n",
    "           \n",
    "def compute_confidence_scores(run_ids, model_type, dataset):\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    \n",
    "    for run_id in run_ids:\n",
    "        train_df, test_df = get_confidence_scores(run_id)\n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "    \n",
    "    df_train = pd.concat(train_dfs, axis=1)\n",
    "    df_test = pd.concat(test_dfs, axis=1)\n",
    "    \n",
    "    for df, label in zip([df_train, df_test], ['train', 'test']):\n",
    "        df_true = pd.read_csv(f'{source_dir}/{dataset}/{label}.csv').target\n",
    "        if model_type == 'SVM':\n",
    "            df_c = pd.DataFrame({'mean': df['certainty'], 'count': 1, 'std': 0})\n",
    "            df_c['p_true'] = (df.prediction == df_true).astype(float)\n",
    "            df_c['cnt_unique'] = 1.0\n",
    "            df_c['p_mf'] = 1.0\n",
    "        else:\n",
    "            df_c = df.certainty.agg(['mean', 'count', 'std'], axis=1)\n",
    "            df_c['p_true'] = df.prediction.apply(lambda s: s.eq(df_true)).sum(axis=1)/df_c['count']\n",
    "            df_c['cnt_unique'] = df.prediction.apply(lambda row: len(np.unique(row.values)) , axis = 1)\n",
    "            df_c['p_mf'] = df.prediction.apply(lambda row: np.unique(row.values, return_counts=True)[1].max(), axis = 1)/df_c['count'] # probability of most frequent prediction\n",
    "        df_c['ci95'] = 1.96*df_c['std']/df_c['count']**.5\n",
    "        df_c[['mean', 'std', 'ci95', 'p_true', 'p_mf', 'cnt_unique']].to_csv(f'confidence/confidence_{model_type}_{dataset}_{label}.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4def31-03d1-4b54-8743-9add577e8274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION_TREE--TREC-6 already processed\n",
      "DECISION_TREE--DBP-14 already processed\n",
      "DECISION_TREE--YELP-5 already processed\n",
      "DECISION_TREE--GERMEVAL-2020 already processed\n",
      "DECISION_TREE--GERMEVAL-2018 already processed\n",
      "DECISION_TREE--10K-GNAD already processed\n",
      "RANDOM_FOREST--YELP-5 already processed\n",
      "RANDOM_FOREST--DBP-14 already processed\n",
      "RANDOM_FOREST--TREC-6 already processed\n",
      "RANDOM_FOREST--10K-GNAD already processed\n",
      "RANDOM_FOREST--GERMEVAL-2018 already processed\n",
      "RANDOM_FOREST--GERMEVAL-2020 already processed\n",
      "FASTTEXT--DBP-14 already processed\n",
      "FASTTEXT--TREC-6 already processed\n",
      "FASTTEXT--YELP-5 already processed\n",
      "FASTTEXT--10K-GNAD already processed\n",
      "FASTTEXT--GERMEVAL-2018 already processed\n",
      "FASTTEXT--GERMEVAL-2020 already processed\n",
      "GERMAN_BERT--10K-GNAD already processed\n",
      "GERMAN_BERT--GERMEVAL-2018 already processed\n",
      "GERMAN_BERT--GERMEVAL-2020 already processed\n",
      "SVM--YELP-5 already processed\n",
      "SVM--DBP-14 already processed\n",
      "SVM--TREC-6 already processed\n",
      "SVM--10K-GNAD already processed\n",
      "SVM--GERMEVAL-2018 already processed\n",
      "SVM--GERMEVAL-2020 already processed\n",
      "BERT--DBP-14 already processed\n",
      "BERT--TREC-6 already processed\n",
      "BERT--YELP-5 already processed\n"
     ]
    }
   ],
   "source": [
    "is_rerun = False\n",
    "\n",
    "for idx, row in df_exp[['model_type', 'dataset']].drop_duplicates().iterrows():\n",
    "    model_type = row['model_type']\n",
    "    dataset = row['dataset']\n",
    "    if not is_rerun and os.path.exists(f'confidence/confidence_{model_type}_{dataset}_train.csv') and os.path.exists(f'confidence/confidence_{model_type}_{dataset}_test.csv'):\n",
    "        print(f'{model_type}--{dataset} already processed')\n",
    "        continue\n",
    "    \n",
    "    print(f'Processing {model_type}--{dataset}')\n",
    "    run_ids = df_exp[(df_exp.model_type == model_type) & (df_exp.dataset == dataset)].run_id.values\n",
    "    compute_confidence_scores(run_ids, model_type, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f2de5-2a51-4107-90ef-321291ac6ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
